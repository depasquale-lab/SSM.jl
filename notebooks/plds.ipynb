{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using SSM\n",
    "using Random\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "using Plots\n",
    "using ForwardDiff\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(123)\n",
    "\n",
    "function toy_PoissonLDS()\n",
    "    T = 100\n",
    "    # create a PLDS model\n",
    "    x0 = [1.0, -1.0]\n",
    "    p0 = Matrix(Diagonal([0.001, 0.001]))\n",
    "    A = [cos(0.1) -sin(0.1); sin(0.1) cos(0.1)]\n",
    "    Q = Matrix(Diagonal([0.001, 0.001]))\n",
    "    C = [0.05 0.05; 0.05 0.01; 0.1 0.01]\n",
    "    log_d = log.([0.05, 0.05, 1.])\n",
    "    D = Matrix(Diagonal([0., 0., 0.]))\n",
    "    b = ones(T, 2) * 0.01\n",
    "\n",
    "    plds = PoissonLDS(A=A, C=C, Q=Q, D=D, b=b, log_d=log_d, x0=x0, p0=p0, refractory_period=1, obs_dim=3, latent_dim=2)\n",
    "    # sample data\n",
    "    x, y = SSM.sample(plds, T, 3)\n",
    "    return plds, x, y\n",
    "end\n",
    "\n",
    "plds, x, y = toy_PoissonLDS()\n",
    "\n",
    "# model = SSM.PoissonPCA(;latent_dim=2, obs_dim=3)\n",
    "# lls = fit!(model, y[1, :, :], 20)\n",
    "\n",
    "b = ones(100, 2) * 0.005;\n",
    "plds.A = Matrix{Float64}([0.1 0.; 0. 0.1])\n",
    "plds.Q = Matrix{Float64}([0.1 0; 0 0.1])\n",
    "plds.x0 = [0.0, -0.0]\n",
    "plds.p0 = Matrix{Float64}([0.1 0; 0 0.1])\n",
    "plds.b = b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-571.0573778719382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E_z, E_zz, E_zz_prev, x_sm, p_sm = SSM.E_Step(plds, y)\n",
    "\n",
    "function Q_initial_obs(x0::Vector{<:Real}, sqrt_p0::Matrix{<:Real}, E_z::Array{<:Real}, E_zz::Array{<:Real})\n",
    "    # reparametrize p0\n",
    "    p0 = sqrt_p0 * sqrt_p0'\n",
    "    # Compute Q\n",
    "    Q_val = 0.0\n",
    "    trials = size(E_z, 1)\n",
    "    for k in 1:trials\n",
    "        Q_val += -0.5 * (logdet(p0) + tr(inv(p0) * (E_zz[k, 1, :, :] - 2*(E_z[k, 1, :] * x0') + (x0 * x0'))))\n",
    "    end\n",
    "    return Q_val\n",
    "end\n",
    "\n",
    "function Q_state_model(A::Matrix{<:Real}, sqrt_Q::Matrix{<:Real}, E_zz::Array{<:Real}, E_zz_prev::Array{<:Real})\n",
    "    # reparametrize Q\n",
    "    Q = sqrt_Q * sqrt_Q'\n",
    "    Q_inv = pinv(Q)\n",
    "    # Compute Q\n",
    "    Q_val = 0.0\n",
    "    trials = size(E_zz, 1)\n",
    "    time_steps = size(E_zz, 2)\n",
    "    for k in 1:trials\n",
    "        for t in 2:time_steps\n",
    "            term1 = E_zz[k, t, :, :]\n",
    "            term2 = A * E_zz_prev[k, t, :, :]'\n",
    "            term3 = E_zz_prev[k, t, :, :] * A'\n",
    "            term4 = A * E_zz[k, t-1, :, :] * A'\n",
    "            Q_val += -0.5 * (logdet(Q) + tr(Q_inv * (term1 - term2 - term3 + term4)))\n",
    "        end\n",
    "    end\n",
    "    return Q_val\n",
    "end\n",
    "\n",
    "function Q_observation_model(C::Matrix{<:Real}, D::Matrix{<:Real}, log_d::Vector{<:Real}, E_z::Array{<:Real}, E_zz::Array{<:Real}, y::Array{<:Real})\n",
    "    # Re-parametrize log_d\n",
    "    d = exp.(log_d)\n",
    "    # Compute Q\n",
    "    Q_val = 0.0\n",
    "    trials = size(E_z, 1)\n",
    "    time_steps = size(E_z, 2)\n",
    "    # sum over trials\n",
    "    for k in 1:trials\n",
    "        spikes = SSM.countspikes(y[k, :, :])\n",
    "        # sum over time-points\n",
    "        for t in 1:time_steps\n",
    "            # linear term\n",
    "            term_1 = y[k, t, :]' * (C * E_z[k, t, :] + D*spikes[t, :] + d)\n",
    "            # first part of quadratic term (sum over neurons)\n",
    "            term_2 = sum(exp.(C * E_z[k, t, :] + D*spikes[t, :] + d))\n",
    "            # second part of quadratic term (sum over neurons)\n",
    "            term_3 = 0.0\n",
    "            for i in axes(C, 1)\n",
    "                term_3 += 0.5 * C[i, :]' * E_zz[k, t, :, :] * C[i, :]\n",
    "            end\n",
    "            Q_val += term_1 - term_2 + term_3\n",
    "        end\n",
    "    end\n",
    "    return Q_val\n",
    "end\n",
    "\n",
    "Q_observation_model(plds.C, plds.D, plds.log_d, E_z, E_zz, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       "  5.82607e-9   -4.28744e-11\n",
       " -4.27871e-11   5.6684e-9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# param_update = Matrix(cholesky((dropdims(sum(p_sm[:, 1, :, :], dims=1)./3, dims=1) + dropdims(sum(p_sm[:, 1, :, :], dims=1)./3, dims=1)') / 2))\n",
    "# p0_l = Matrix(cholesky(plds.p0).L)\n",
    "grad_p0 = ForwardDiff.gradient(p0 -> Q_initial_obs(plds.x0, p0, E_z, E_zz), result_p0.minimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix{Float64}\u001b[90m (alias for \u001b[39m\u001b[90mArray{Float64, 2}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(result_p0.minimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       "  0.0996733  -5.9114e-5\n",
       " -5.9114e-5   0.0999697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(dropdims(sum(p_sm[:, 1, :, :], dims=1)./3, dims=1) + dropdims(sum(p_sm[:, 1, :, :], dims=1)./3, dims=1)') / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       "  0.0997496   -4.96169e-5\n",
       " -4.96169e-5   0.0999744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optimize x0 and p0\n",
    "opt_x0 = x0 -> -Q_initial_obs(x0, plds.p0, E_z, E_zz)\n",
    "opt_p0 = p0 -> -Q_initial_obs(plds.x0, p0, E_z, E_zz)\n",
    "\n",
    "result_x0 = optimize(opt_x0, plds.x0, LBFGS())\n",
    "result_p0 = optimize(opt_p0, plds.p0, LBFGS())\n",
    "\n",
    "result_x0.minimizer\n",
    "result_p0.minimizer * result_p0.minimizer'\n",
    "\n",
    "# @assert isapprox(result_x0.minimizer, SSM.update_initial_state_mean!(plds, E_z))\n",
    "# @assert isapprox(result_p0.minimizer * result_p0.minimizer', SSM.update_initial_state_covariance!(plds, E_zz, E_z), atol=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.315832     7.85007e-5\n",
       "  7.85102e-5  -0.316187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_p0.minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize A and Q\n",
    "opt_A = A -> -Q_state(A, plds.Q, E_zz, E_zz_prev)\n",
    "result_A = optimize(opt_A, plds.A, LBFGS())\n",
    "\n",
    "@assert isapprox(result_A.minimizer, SSM.update_A_plds!(plds, E_zz, E_zz_prev), atol=1e-6)\n",
    "\n",
    "# if pass assertion, update the model\n",
    "plds.A = result_A.minimizer\n",
    "\n",
    "# optimize Q now\n",
    "opt_Q = Q -> -Q_state(plds.A, Q, E_zz, E_zz_prev)\n",
    "result_Q = optimize(opt_Q, plds.Q, LBFGS())\n",
    "\n",
    "@assert isapprox(result_Q.minimizer * result_Q.minimizer', SSM.update_Q_plds!(plds, E_zz, E_zz_prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  332.400 μs (4893 allocations: 277.09 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-203.40715212110916"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function countspikes(y::Matrix{<:Real}, window::Int=1)\n",
    "    # Get size of the observation matrix\n",
    "    T, D = size(y)\n",
    "    # Initialize the spike-count matrix\n",
    "    s = zeros(T, D)\n",
    "    # Compute the cumulative sum of the observation matrix along the first dimension (time)\n",
    "    cumsum_y = cumsum(y, dims=1)\n",
    "    \n",
    "    # Loop over time points from 2 to T\n",
    "    for t in 2:T\n",
    "        if t - window <= 1\n",
    "            # If the time window is less than or equal to 1, use the cumulative sum directly\n",
    "            s[t, :] = cumsum_y[t-1, :]\n",
    "        else\n",
    "            # Otherwise, calculate the sum of the window by subtracting cumulative sums\n",
    "            s[t, :] = cumsum_y[t-1, :] .- cumsum_y[t-window-1, :]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return s\n",
    "end\n",
    "\n",
    "function logposterior_nonthreaded(x::AbstractMatrix{<:Real}, plds::PoissonLDS, y::Matrix{<:Real}) \n",
    "    # Re-parameterize log_d\n",
    "    d = exp.(plds.log_d)\n",
    "    # Calculate the log-posterior\n",
    "    T = size(y, 1)\n",
    "    # Get an array of prior spikes\n",
    "    s = countspikes(y, plds.refractory_period)\n",
    "    # calculate the first term\n",
    "    pygivenx = 0.0\n",
    "    for t in 1:T\n",
    "        pygivenx += (y[t, :]' * ((plds.C * x[t, :]) + (plds.D * s[t, :]) + d)) - sum(exp.((plds.C * x[t, :]) + (plds.D * s[t, :]) + d))\n",
    "    end\n",
    "    # calculate the second term\n",
    "    px1 = -0.5 * (x[1, :] - plds.x0)' * pinv(plds.p0) * (x[1, :] - plds.x0)\n",
    "    # calculate the last term\n",
    "    pxtgivenxt1 = 0.0\n",
    "    for t in 2:T\n",
    "        pxtgivenxt1 += -0.5 * (x[t, :] - ((plds.A * x[t-1, :]) + plds.b[t, :]))' * pinv(plds.Q) * (x[t, :] - ((plds.A * x[t-1, :]) + plds.b[t, :])) \n",
    "    end\n",
    "    # sum the terms\n",
    "    return pygivenx + px1 + pxtgivenxt1\n",
    "end\n",
    "@btime logposterior(zeros(100, 2), plds, y[1, :, :])\n",
    "# obj = x -> -logposterior(x, plds, y[1, :, :])\n",
    "\n",
    "# using ForwardDiff \n",
    "# ForwardDiff.gradient(obj, zeros(100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Zygote.CompileError",
     "evalue": "Compiling Tuple{typeof(Base._wait), Task}: try/catch is not supported.\nRefer to the Zygote documentation for fixes.\nhttps://fluxml.ai/Zygote.jl/latest/limitations\n",
     "output_type": "error",
     "traceback": [
      "Compiling Tuple{typeof(Base._wait), Task}: try/catch is not supported.\n",
      "Refer to the Zygote documentation for fixes.\n",
      "https://fluxml.ai/Zygote.jl/latest/limitations\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      "  [1] macro expansion\n",
      "    @ C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:113 [inlined]\n",
      "  [2] _pullback(ctx::Zygote.Context{false}, f::typeof(Base._wait), args::Task)\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:113\n",
      "  [3] _pullback\n",
      "    @ .\\threadingconstructs.jl:152 [inlined]\n",
      "  [4] _pullback(::Zygote.Context{false}, ::typeof(Base.Threads.threading_run), ::var\"#213#threadsfor_fun#41\"{var\"#213#threadsfor_fun#39#42\"{Matrix{Float64}, PoissonLDS, Matrix{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}, UnitRange{Int64}}}, ::Bool)\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:0\n",
      "  [5] _pullback\n",
      "    @ .\\threadingconstructs.jl:205 [inlined]\n",
      "  [6] _pullback(::Zygote.Context{false}, ::typeof(logposterior), ::Matrix{Float64}, ::PoissonLDS, ::Matrix{Float64})\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:0\n",
      "  [7] _pullback\n",
      "    @ c:\\Users\\ryansenne\\Documents\\GitHub\\ssm_julia\\notebooks\\plds.ipynb:31 [inlined]\n",
      "  [8] _pullback(ctx::Zygote.Context{false}, f::var\"#45#46\", args::Matrix{Float64})\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface2.jl:0\n",
      "  [9] pullback(f::Function, cx::Zygote.Context{false}, args::Matrix{Float64})\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface.jl:90\n",
      " [10] pullback\n",
      "    @ C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface.jl:88 [inlined]\n",
      " [11] gradient(f::Function, args::Matrix{Float64})\n",
      "    @ Zygote C:\\Users\\ryansenne\\.julia\\packages\\Zygote\\nsBv0\\src\\compiler\\interface.jl:147\n",
      " [12] top-level scope\n",
      "    @ c:\\Users\\ryansenne\\Documents\\GitHub\\ssm_julia\\notebooks\\plds.ipynb:32"
     ]
    }
   ],
   "source": [
    "using Base.Threads\n",
    "using BenchmarkTools\n",
    "\n",
    "function logposterior(x::AbstractMatrix{<:Real}, plds::PoissonLDS, y::Matrix{<:Real})\n",
    "    # Convert the log firing rate to firing rate\n",
    "    d = exp.(plds.log_d)\n",
    "    T = size(y, 1)\n",
    "    s = countspikes(y, plds.refractory_period)\n",
    "    # Get the number of time steps\n",
    "    pygivenx = zeros(T)\n",
    "    # Calculate p(yₜ|xₜ)\n",
    "    @threads for t in 1:T\n",
    "        temp = (plds.C * x[t, :] .+ plds.D * s[t, :] .+ d)\n",
    "        pygivenx[t] = (y[t, :]' * temp) - sum(exp.(temp))\n",
    "    end\n",
    "    pygivenx_sum = sum(pygivenx)\n",
    "    # Calculate p(x₁)\n",
    "    px1 = -0.5 * (x[1, :] .- plds.x0)' * pinv(plds.p0) * (x[1, :] .- plds.x0)\n",
    "    # Calculate p(xₜ|xₜ₋₁)\n",
    "    pxtgivenxt1 = zeros(T-1)\n",
    "    @threads for t in 2:T\n",
    "        temp = (x[t, :] .- (plds.A * x[t-1, :] .+ plds.b[t, :]))\n",
    "        pxtgivenxt1[t-1] = -0.5 * temp' * pinv(plds.Q) * temp\n",
    "    end\n",
    "    pxtgivenxt1_sum = sum(pxtgivenxt1)\n",
    "    # Return the log-posterior\n",
    "    return pygivenx_sum + px1 + pxtgivenxt1_sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.09964753619401641 -6.171103550769067e-5; 0.10063365806081821 -6.414153286612634e-5; … ; 0.10069165946854451 -5.933540801424813e-5; 0.10069680914924041 -5.8432329248563064e-5;;; -6.171103550768466e-5 0.09996948579925777; -6.414153286613473e-5 0.10096827160413231; … ; -5.933540801424887e-5 0.10097872615981948; -5.8432329248559595e-5 0.10097917916072414], [0.009929308717424798 -1.2375836282808027e-5; 0.01002731642289832 -1.2729857659660688e-5; … ; 0.010037861736130216 -1.1761267247855036e-5; 0.010038559471751356 -1.1640917676080294e-5;;; -1.2375837256344493e-5 0.009993872511605752; -1.2729879043070484e-5 0.010093691994177598; … ; -1.1761281080845925e-5 0.010094786682380183; -1.1640936728077284e-5 0.010094846290284554])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H, main, super, sub = SSM.Hessian(x[1, :, :], plds, y[1, :, :])\n",
    "p_sm, ptt1 = SSM.block_tridiagonal_inverse(-sub, -main, -super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.01727703627004362 -0.02090831686249808; -0.04152467064665573 0.01935306490561603; … ; -0.0007752634189086974 0.001402238832428847; -0.0032608823985584316 -0.006620031372885339],  * Status: failure (reached maximum number of iterations)\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     2.036107e+02\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Newton's Method\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 2.29e-05 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 5.52e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 2.04e-04 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 1.00e-06 ≰ 0.0e+00\n",
       "    |g(x)|                 = 6.05e-01 ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   97  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    64046\n",
       "    ∇f(x) calls:   64046\n",
       "    ∇²f(x) calls:  1001\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wrapper function for the objective (negative log-posterior)\n",
    "function objective(x_vec::Vector{T}, plds::PoissonLDS, y::Matrix{T}) where T<:Real\n",
    "    T_steps, latent_dim = size(y, 1), plds.latent_dim\n",
    "    x = interleave_reshape(x_vec, T_steps, latent_dim)\n",
    "    return -logposterior(x, plds, y)\n",
    "end\n",
    "\n",
    "# Wrapper function for the gradient\n",
    "function gradient!(G::Vector{T}, x_vec::Vector{T}, plds::PoissonLDS, y::Matrix{T}) where T<:Real\n",
    "    T_steps, latent_dim = size(y, 1), plds.latent_dim\n",
    "    x = interleave_reshape(x_vec, T_steps, latent_dim)\n",
    "    grad = SSM.Gradient(x, plds, y)\n",
    "    G .= vec(grad)\n",
    "end\n",
    "\n",
    "# Wrapper function for the Hessian\n",
    "function hessian!(H::Matrix{T}, x_vec::Vector{T}, plds::PoissonLDS, y::Matrix{T}) where T<:Real\n",
    "    T_steps, latent_dim = size(y, 1), plds.latent_dim\n",
    "    x = interleave_reshape(x_vec, T_steps, latent_dim)\n",
    "    hess, _, _, _ = SSM.Hessian(x, plds, y)\n",
    "    H .= hess\n",
    "end\n",
    "\n",
    "# Function to run the optimization\n",
    "function optimize_latent_states(initial_x::Matrix{T}, plds::PoissonLDS, y::Matrix{T}) where T<:Real\n",
    "    T_steps, latent_dim = size(initial_x)\n",
    "    \n",
    "    # Create wrapper functions with fixed plds and y\n",
    "    f(x) = objective(x, plds, y)\n",
    "    g!(G, x) = gradient!(G, x, plds, y)\n",
    "    h!(H, x) = hessian!(H, x, plds, y)\n",
    "    \n",
    "    # Flatten the initial guess\n",
    "    initial_x_vec = vec(permutedims(initial_x))\n",
    "    \n",
    "    # Set up the optimization problem\n",
    "    result = optimize(f, g!, h!, initial_x_vec)\n",
    "    \n",
    "    # Reshape the result back to a matrix\n",
    "    optimal_x = interleave_reshape(result.minimizer, T_steps, latent_dim)\n",
    "    \n",
    "    return optimal_x, result\n",
    "end\n",
    "\n",
    "optimize_latent_states(zeros(100, 2), plds, y[1, :, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.013369048145516576 0.0007830711933090716; 0.01742122896861685 0.003249000830713299; … ; 0.015695964843495183 0.005740105402084179; 0.013825347030947756 0.006538013121058254], [0.0996730428873636 -5.9159419522603635e-5; 0.10066312523569919 -6.095100068439873e-5; … ; 0.10067315667024221 -6.09683215243662e-5; 0.10067647846717766 -6.036991281801671e-5;;; -5.915941952260452e-5 0.09996966659552509; -6.095100068438583e-5 0.10096874712805827; … ; -6.096832152437012e-5 0.10097883664292145; -6.036991281802365e-5 0.10097914348996768], [0.0 0.0; 0.009934705099655475 -1.1813006990574534e-5; … ; 0.010034513924107511 -1.2034454505465084e-5; 0.010034726686880257 -1.199274956016177e-5;;; 0.0 0.0; -1.181300610629099e-5 0.009993936682818378; … ; -1.203444189415753e-5 0.010094830792888657; -1.1992750437381327e-5 0.010094853896451077])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sm, p_sm, ptt1 = SSM.directsmooth(plds, y[1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.245004513516506e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maximum(SSM.Gradient(x_sm, plds, y[1, :, :]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
