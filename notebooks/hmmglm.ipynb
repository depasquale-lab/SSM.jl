{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `\\Users\\ryansenne\\Documents\\Github\\SSM`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/Users/ryansenne/Documents/Github/SSM/\")\n",
    "# Pkg.activate(\"/home/ryansenne/PycharmProjects/ssm_julia/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/Users/ryansenne/Documents/Github/SSM//src/SSM.jl\")\n",
    "# include(\"/home/ryansenne/PycharmProjects/ssm_julia/src/SSM.jl\")\n",
    "using Random\n",
    "using .SSM\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian GLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.963508062948609\n",
       "  3.0472521214354646\n",
       " -4.032847152584493\n",
       "  5.085586252239004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a Gaussian GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3);  # 100 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "y = X_concat * β + rand(Normal(0, 1), 10000)\n",
    "\n",
    "# define a GLM\n",
    "glm = GaussianRegression(X, y)\n",
    "fit!(glm, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson GLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.9972876910665238\n",
       "  3.0018761978448465\n",
       " -4.001568346180793\n",
       "  5.002617122785103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a Poisson GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3);  # 100 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y = Vector{Float64}(rand.(Poisson.(exp.(X_concat * β))))\n",
    "\n",
    "# define a GLM\n",
    "glm = PoissonRegression(X, y)\n",
    "fit!(glm, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial GLM Example (i.e. logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.8285295895751685\n",
       "  3.0115236069793356\n",
       " -3.778705515037161\n",
       "  5.156155128038023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sigmoid function\n",
    "function sigmoid(x)\n",
    "    return 1 / (1 + exp(-x))\n",
    "end\n",
    "\n",
    "# Fit a Binomial GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3); # 1000 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y = Vector{Float64}(rand.(Binomial.(1, sigmoid.(X_concat * β))))\n",
    "\n",
    "# define a GLM\n",
    "glm = BinomialRegression(X, y)\n",
    "fit!(glm, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538958584342558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate AR(1) model\n",
    "init_val = 0.0\n",
    "phi = 0.9\n",
    "sigma = 1.0\n",
    "T = 1000\n",
    "y = Vector{Float64}(undef, T)\n",
    "y[1] = init_val\n",
    "for t in 2:T\n",
    "    y[t] = phi * y[t-1] + rand(Normal(0, sigma))\n",
    "end\n",
    "\n",
    "ar_1 = Autoregression(y, 1)\n",
    "fit!(ar_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Log-likelihood: -8924.586743524973\n",
      "Iteration: 2, Log-likelihood: -8739.362326611385\n",
      "Iteration: 3, Log-likelihood: -8590.645568136204\n",
      "Iteration: 4, Log-likelihood: -8487.922486518475\n",
      "Iteration: 5, Log-likelihood: -8425.134856905965\n",
      "Iteration: 6, Log-likelihood: -8388.1560823782\n",
      "Iteration: 7, Log-likelihood: -8366.508137598063\n",
      "Iteration: 8, Log-likelihood: -8354.032129290421\n",
      "Iteration: 9, Log-likelihood: -8347.05339618205\n",
      "Iteration: 10, Log-likelihood: -8343.28945695505\n",
      "Iteration: 11, Log-likelihood: -8341.336144244464\n",
      "Iteration: 12, Log-likelihood: -8340.358723752062\n",
      "Iteration: 13, Log-likelihood: -8339.884591585684\n",
      "Iteration: 14, Log-likelihood: -8339.660157362405\n",
      "Iteration: 15, Log-likelihood: -8339.55583983571\n",
      "Iteration: 16, Log-likelihood: -8339.507983863976\n",
      "Convergence reached at iteration 16\n",
      "3.0470238249608047e12\n",
      "2.736186558656916e12\n",
      "Initial Variance: [1.5242740495051548e9, 1.3687776681625392e9]\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 1: -1.661341605283923e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 2: -1.6602038867771173e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 3: -1.6586603639019309e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 4: -1.657084862102203e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 5: -1.6570848612305664e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 6: -1.6570848612305664e7\n"
     ]
    }
   ],
   "source": [
    "# try out markov glm\n",
    "\n",
    "# Generate synthetic data from two distinct regimes\n",
    "X = rand(1000, 3); # 1000 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(1000), X)\n",
    "β₁ = [-20, -30, -40, 50]\n",
    "β₂ = [6, 7, 8, -9]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y₁ = X_concat * β₁ + rand(Normal(0, 0.1), 1000)\n",
    "y₂ = X_concat * β₂ + rand(Normal(0, 1), 1000)\n",
    "\n",
    "# concatenate X1 and X2\n",
    "x = vcat(X, X)\n",
    "\n",
    "# concatenate y1 and y2\n",
    "y = vcat(y₁, y₂)\n",
    "\n",
    "# define a Gaussian HMMGLM\n",
    "glm = SwitchingGaussianRegression(y, x, 2)\n",
    "\n",
    "MarkovRegressionEM(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " -19.8170073700559\n",
       " -28.185869452125555\n",
       " -37.88979160361808\n",
       "  47.35209106013571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.B[2].regression_model.β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " NaN\n",
       " NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.σ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " -20.058395420154884\n",
       " -28.413295346218813\n",
       " -38.62800924981708\n",
       "  48.29198573140382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.B[2].regression_model.β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinearAlgebra.LAPACKException",
     "evalue": "LinearAlgebra.LAPACKException(2)",
     "output_type": "error",
     "traceback": [
      "LinearAlgebra.LAPACKException(2)\n",
      "\n",
      "Stacktrace:\n",
      " [1] chklapackerror\n",
      "   @ C:\\Users\\ryansenne\\AppData\\Local\\Programs\\Julia-1.9.3\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\lapack.jl:40 [inlined]\n",
      " [2] trtrs!(uplo::Char, trans::Char, diag::Char, A::Matrix{Float64}, B::Matrix{Float64})\n",
      "   @ LinearAlgebra.LAPACK C:\\Users\\ryansenne\\AppData\\Local\\Programs\\Julia-1.9.3\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\lapack.jl:3424\n",
      " [3] ldiv!\n",
      "   @ C:\\Users\\ryansenne\\AppData\\Local\\Programs\\Julia-1.9.3\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\triangular.jl:727 [inlined]\n",
      " [4] inv(A::LinearAlgebra.UpperTriangular{Float64, Matrix{Float64}})\n",
      "   @ LinearAlgebra C:\\Users\\ryansenne\\AppData\\Local\\Programs\\Julia-1.9.3\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\triangular.jl:809\n",
      " [5] inv(A::Matrix{Int64})\n",
      "   @ LinearAlgebra C:\\Users\\ryansenne\\AppData\\Local\\Programs\\Julia-1.9.3\\share\\julia\\stdlib\\v1.9\\LinearAlgebra\\src\\dense.jl:913\n",
      " [6] inverse_block_tridiagonal(A_blocks::Vector{Matrix{Int64}}, B_blocks::Vector{Matrix{Int64}}, C_blocks::Vector{Matrix{Int64}})\n",
      "   @ Main c:\\Users\\ryansenne\\Documents\\GitHub\\SSM\\notebooks\\hmmglm.ipynb:52\n",
      " [7] top-level scope\n",
      "   @ c:\\Users\\ryansenne\\Documents\\GitHub\\SSM\\notebooks\\hmmglm.ipynb:83"
     ]
    }
   ],
   "source": [
    "function inverse_tridiagonal(A)\n",
    "    N = size(A, 1)\n",
    "    \n",
    "    # Initialize vectors and matrices\n",
    "    D = zeros(N)\n",
    "    E = zeros(N)\n",
    "    Z = zeros(N, N)\n",
    "    W = zeros(N, N)\n",
    "    λ = zeros(N, N)\n",
    "\n",
    "    # Boundary conditions\n",
    "    D[1] = 0\n",
    "    E[N] = 0\n",
    "    Z[:, 1] = 0\n",
    "    W[:, N] = 0\n",
    "\n",
    "    for i = 2:N\n",
    "        # Forward sweep for D and Z\n",
    "        D[i] = (A[i, i] - A[i, i-1] * D[i-1])^-1\n",
    "        for j = 1:i-1\n",
    "            Z[i, j] = -D[i] * (A[i, i-1] * Z[i-1, j])\n",
    "        end\n",
    "\n",
    "        # Reverse sweep for E and W\n",
    "        E[N-i+1] = (A[N-i+1, N-i+1] - A[N-i+1, N-i+2] * E[N-i+2])^-1\n",
    "        for j = N:-1:N-i+2\n",
    "            W[N-i+1, j] = -E[N-i+1] * (A[N-i+1, N-i+2] * W[N-i+2, j])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Compute the diagonal of the inverse\n",
    "    for i = 1:N\n",
    "        λ[i, i] = (1 - D[i] * E[i+1])^-1 * (A[i, i] - A[i, i-1] * D[i-1])^-1\n",
    "        if i < N\n",
    "            λ[i+1, i] = E[i+1] * λ[i, i]\n",
    "            λ[i, i+1] = D[i] * λ[i+1, i+1] + Z[i, i+1]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return λ\n",
    "end\n",
    "\n",
    "function inverse_block_tridiagonal(A_blocks, B_blocks, C_blocks)\n",
    "    N = length(A_blocks)\n",
    "    \n",
    "    # Initialize block vectors and matrices\n",
    "    D_blocks = [zeros(size(A_blocks[1])) for _ in 1:N]\n",
    "    E_blocks = [zeros(size(A_blocks[1])) for _ in 1:N]\n",
    "    λ_blocks = [zeros(size(A_blocks[1])) for _ in 1:N]\n",
    "    \n",
    "    # Forward sweep\n",
    "    D_blocks[1] = inv(A_blocks[1])\n",
    "    for i = 2:N\n",
    "        D_blocks[i] = inv(A_blocks[i] - B_blocks[i-1] * D_blocks[i-1] * C_blocks[i-1])\n",
    "    end\n",
    "\n",
    "    # Reverse sweep\n",
    "    E_blocks[N] = inv(A_blocks[N])\n",
    "    for i = N-1:-1:1\n",
    "        E_blocks[i] = inv(A_blocks[i] - C_blocks[i] * E_blocks[i+1] * B_blocks[i])\n",
    "    end\n",
    "\n",
    "    # Compute the diagonal blocks of the inverse\n",
    "    λ_blocks[1] = inv(I - D_blocks[1] * E_blocks[2]) * D_blocks[1]\n",
    "    for i = 2:N-1\n",
    "        λ_blocks[i] = inv(I - D_blocks[i] * E_blocks[i+1]) * D_blocks[i]\n",
    "    end\n",
    "    λ_blocks[N] = inv(I - D_blocks[N] * E_blocks[N]) * D_blocks[N]\n",
    "    \n",
    "    # Create the inverse matrix from the block diagonals\n",
    "    # inv_matrix = BlockDiagonal(λ_blocks)\n",
    "\n",
    "    return λ_blocks\n",
    "end\n",
    "\n",
    "\n",
    "a = [[1 2; 0 0], [3 4; 5 0], [0 6; 7 8], [0 0; 9 10]]\n",
    "\n",
    "b = [[1 2; 0 0], [3 4; 5 0], [0 6; 7 8], [0 0; 9 10]]\n",
    "\n",
    "c = [[1 2; 0 0], [3 4; 5 0], [0 6; 7 8], [0 0; 9 10]]\n",
    "\n",
    "inverse_block_tridiagonal(a, b, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
