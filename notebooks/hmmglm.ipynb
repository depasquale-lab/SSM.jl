{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SSM\n",
    "using Random\n",
    "using Distributions\n",
    "using Plots\n",
    "using LinearAlgebra\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18667×1 Matrix{Float64}:\n",
       " -10.0\n",
       "  20.0\n",
       "  -6.0\n",
       "  -3.0\n",
       "   4.0\n",
       "   4.0\n",
       "  -2.0\n",
       "   5.0\n",
       "   5.0\n",
       " -10.0\n",
       "   ⋮\n",
       "  -4.0\n",
       "   4.0\n",
       "  -2.0\n",
       "   3.0\n",
       "   6.0\n",
       "   2.0\n",
       "  -6.0\n",
       "  -5.0\n",
       "  -6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robert = CSV.read(\"/Users/ryansenne/Downloads/robert_deltaflash_choice.csv\", DataFrame)\n",
    "# extract variables\n",
    "choice = Array{Float64}(robert.choice)\n",
    "delta_flashes = reshape(Array{Float64}(robert.delta_flashes), length(choice), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = SSM.BernoulliRegression(;λ=0.0)\n",
    "reg_model.β = [0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#11 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = rand(length(choice))\n",
    "obj = β -> -SSM.loglikelihood(SSM.BernoulliRegression(β, true, 0.0), delta_flashes, choice, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.397990388649346\n",
       " 0.2653700973088059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit!(reg_model, delta_flashes, choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     8.983387e+03\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     L-BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 6.79e-08 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.71e-07 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 6.18e-11 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 6.88e-15 ≰ 0.0e+00\n",
       "    |g(x)|                 = 2.40e-09 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    8\n",
       "    f(x) calls:    46\n",
       "    ∇f(x) calls:   46\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using StatsFuns\n",
    "using Optim \n",
    "\n",
    "# function loglikelihood(β, X, y, w)\n",
    "#     p = SSM.logistic.(X * β)\n",
    "#     # clamp probabilities to avoid log(0) and log(1)\n",
    "#     p = clamp.(p, 1e-16, 1-1e-16)\n",
    "#     return -sum(w .* (y .* log.(p) + (1 .- y) .* log.(1 .- p)))\n",
    "# end\n",
    "\n",
    "# function grad!(g, β, X, y, w)\n",
    "#     p = SSM.logistic.(X * β)\n",
    "#     p = clamp.(p, 1e-16, 1-1e-16)\n",
    "#     g .= -X' * (w .* (y .- p))\n",
    "# end\n",
    "\n",
    "w = ones(length(choice))\n",
    "\n",
    "obj = β -> -SSM.loglikelihood(SSM.BernoulliRegression(β, true, 0.0), delta_flashes, choice, w)\n",
    "\n",
    "g! = (g, β) -> SSM.gradient!(g, BernoulliRegression(β, true, 0.0), hcat(ones(length(delta_flashes)), delta_flashes), choice, w)\n",
    "\n",
    "# res = optimize(β -> loglikelihood(β, hcat(ones(length(delta_flashes)), delta_flashes), choice, w), g!, zeros(2), LBFGS())\n",
    "res = optimize(obj, g!, zeros(2), LBFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Optim\n",
    "using StatsFuns\n",
    "\n",
    "\"\"\"\n",
    "    BernoulliRegression(β::Vector{<:Real}, include_intercept::Bool, λ::Float64=0.0)\n",
    "\n",
    "Args:\n",
    "- `β::Vector{<:Real}`: Coefficients of the regression model\n",
    "- `include_intercept::Bool`: Whether to include an intercept term in the model\n",
    "- `λ::Float64`: Regularization parameter for the model\n",
    "\n",
    "Constructors:\n",
    "- `BernoulliRegression(; include_intercept::Bool = true, λ::Float64=0.0)`\n",
    "- `BernoulliRegression(β::Vector{<:Real}, include_intercept::Bool, λ::Float64=0.0)`\n",
    "\n",
    "Example:\n",
    "```julia\n",
    "model = BernoulliRegression()\n",
    "model = BernoulliRegression(include_intercept=false, λ=0.1)\n",
    "model = BernoulliRegression([0.1, 0.2], true, 0.1)\n",
    "```\n",
    "\"\"\"\n",
    "mutable struct BernoulliRegression\n",
    "    β::Vector{<:Real}\n",
    "    include_intercept::Bool\n",
    "    λ::Float64\n",
    "    # Empty constructor\n",
    "    function BernoulliRegression(; include_intercept::Bool = true, λ::Float64=0.0) \n",
    "        @assert λ >= 0.0 \"Regularization parameter must be non-negative.\"\n",
    "        new(Vector{Float64}(), include_intercept, λ)\n",
    "    end\n",
    "    # Parametric Constructor\n",
    "    function BernoulliRegression(β::Vector{<:Real}, include_intercept::Bool, λ::Float64=0.0)\n",
    "        @assert λ >= 0.0 \"Regularization parameter must be non-negative.\"\n",
    "        new(β, include_intercept, λ)\n",
    "    end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    loglikelihood(model::BernoulliRegression, X::Matrix{<:Real}, y::Union{Vector{<:Real}, BitVector}, w::Vector{<:Real}=ones(length(y))\n",
    "\n",
    "Calculate the log-likelihood of a Bernoulli regression model.\n",
    "\n",
    "Args:\n",
    "- `model::BernoulliRegression`: Bernoulli regression model\n",
    "- `X::Matrix{<:Real}`: Design matrix\n",
    "- `y::Union{Vector{<:Real}, BitVector}`: Response vector\n",
    "- `w::Vector{<:Real}`: Weights for the observations\n",
    "\n",
    "Example:\n",
    "```julia\n",
    "model = BernoulliRegression()\n",
    "X = rand(100, 2)\n",
    "y = rand(Bool, 100)\n",
    "loglikelihood(model, X, y)\n",
    "```\n",
    "\"\"\"\n",
    "function loglikelihood(model::BernoulliRegression, X::Matrix{<:Real}, y::Vector{<:Real}, w::Vector{<:Real}=ones(length(y)))\n",
    "    # confirm that the model has been fit\n",
    "    @assert !isempty(model.β) \"Model parameters not initialized, please call fit! first.\"\n",
    "    # add intercept if specified and not already included\n",
    "    if model.include_intercept && size(X, 2) == length(model.β) - 1 \n",
    "        X = hcat(ones(size(X, 1)), X)\n",
    "    end\n",
    "    # calculate log likelihood\n",
    "    p = logistic.(X * model.β)\n",
    "    # Clamp probabilities to avoid log(0) and log(1)\n",
    "    p = clamp.(p, 1e-16, 1-1e-16)\n",
    "    return sum(w .* (y .* log.(p) + (1 .- y) .* log.(1 .- p)))\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    loglikelihood(model::BernoulliRegression, X::Vector{<:Real}, y::Union{Float64, Bool, Int64}, w::Float64=1.0)\n",
    "\n",
    "Calculate the log-likelihood of a single observation of a Bernoulli regression model.\n",
    "\n",
    "Args:\n",
    "- `model::BernoulliRegression`: Bernoulli regression model\n",
    "- `X::Vector{<:Real}`: Design vector\n",
    "- `y::Union{Float64, Bool, Int64}`: Response value\n",
    "- `w::Float64`: Weight for the observation\n",
    "\n",
    "Example:\n",
    "```julia\n",
    "model = BernoulliRegression()\n",
    "X = rand(2)\n",
    "y = rand(Bool)\n",
    "loglikelihood(model, X, y)\n",
    "```\n",
    "\"\"\"\n",
    "function loglikelihood(model::BernoulliRegression, X::Vector{<:Real}, y::Union{Float64, Bool, Int64}, w::Float64=1.0)\n",
    "    # confirm that the model has been fit\n",
    "    @assert !isempty(model.β) \"Model parameters not initialized, please call fit! first.\"\n",
    "    # add intercept if specified\n",
    "    if model.include_intercept && length(X) == length(model.β) - 1\n",
    "        X = vcat(1.0, X)\n",
    "    end\n",
    "    # calculate log likelihood\n",
    "    p = logistic.(X' * model.β) # use stats fun for this\n",
    "    # Clamp probabilities to avoid log(0) and log(1)\n",
    "    p = clamp(p, 1e-16, 1-1e-16)\n",
    "    return sum(w .* (y .* log.(p) + (1 .- y) .* log.(1 .- p)))\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    gradient!(grad::Vector{<:Real}, model::BernoulliRegression, X::Matrix{<:Real}, y::Union{Vector{<:Real}, BitVector}, w::Vector{<:Real}=ones(length(y))\n",
    "\n",
    "Calculate the gradient of the negative log-likelihood function for a Bernoulli regression model. \n",
    "\n",
    "Args:\n",
    "- `grad::Vector{<:Real}`: Gradient of the negative log-likelihood function\n",
    "- `model::BernoulliRegression`: Bernoulli regression model\n",
    "- `X::Matrix{<:Real}`: Design matrix\n",
    "- `y::Union{Vector{<:Real}, BitVector}`: Response vector\n",
    "- `w::Vector{<:Real}`: Weights for the observations\n",
    "\"\"\"\n",
    "function gradient!(g::Vector{<:Real}, model::BernoulliRegression, X::Matrix{<:Real}, y::Vector{<:Real}, w::Vector{<:Real}=ones(length(y)))\n",
    "    # Calculate probabilities\n",
    "    p = logistic.(X * model.β)\n",
    "    # Clamp probabilities to avoid log(0) and log(1)\n",
    "    p = clamp.(p, 1e-16, 1-1e-16)\n",
    "    # Calculate gradient\n",
    "    g .= -X' * Diagonal(w) * (y .- p) #+ (2 * model.λ * model.β)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    fit!(model::BernoulliRegression, X::Matrix{<:Real}, y::Union{Vector{<:Real}, BitVector}, w::Vector{<:Real}=ones(length(y))\n",
    "\n",
    "Fit a Bernoulli regression model using maximum likelihood estimation.\n",
    "\n",
    "Args:\n",
    "- `model::BernoulliRegression`: Bernoulli regression model\n",
    "- `X::Matrix{<:Real}`: Design matrix\n",
    "- `y::Union{Vector{<:Real}, BitVector}`: Response vector\n",
    "- `w::Vector{<:Real}`: Weights for the observations\n",
    "\n",
    "Example:\n",
    "```julia\n",
    "model = BernoulliRegression()\n",
    "X = rand(100, 2)\n",
    "y = rand(Bool, 100)\n",
    "fit!(model, X, y)\n",
    "\n",
    "model = BernoulliRegression()\n",
    "X = rand(100, 2)\n",
    "y = rand(Bool, 100)\n",
    "w = rand(100)\n",
    "fit!(model, X, y, w)\n",
    "```\n",
    "\"\"\"\n",
    "function fit!(model::BernoulliRegression, X::Matrix{<:Real}, y::Vector{<:Real}, w::Vector{<:Real}=ones(length(y)))\n",
    "    if model.include_intercept\n",
    "        X = hcat(ones(size(X, 1)), X)\n",
    "    end\n",
    "    p = size(X, 2)\n",
    "    model.β = zeros(p)\n",
    "    y = convert(Vector{Float64}, y)\n",
    "    # print likelihood and grad\n",
    "    println(\"Initial log-likelihood: \", loglikelihood(model, X, y, w))\n",
    "    println(\"Initial gradient: \", gradient!(zeros(p), model, X, y, w))\n",
    "    objective = β -> -loglikelihood(BernoulliRegression(β, model.include_intercept, model.λ), X, y, w)\n",
    "    objective_grad! = (β, g) -> gradient!(g, BernoulliRegression(β, model.include_intercept, model.λ), X, y, w)\n",
    "    result = optimize(objective, objective_grad!, zeros(p), LBFGS(), Optim.Options(show_trace=true))\n",
    "    println(\"Optimization result: \", result)\n",
    "    model.β = result.minimizer\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log-likelihood: -12938.978419512487\n",
      "Initial gradient: [-1011.5, -36503.5]\n",
      "Iter     Function value   Gradient norm \n",
      "     0              NaN              NaN\n",
      " * time: 0.0\n",
      "Optimization result:  * Status: failure\n",
      "\n",
      " * Candidate solution\n",
      "    Final objective value:     NaN\n",
      "\n",
      " * Found with\n",
      "    Algorithm:     L-BFGS\n",
      "\n",
      " * Convergence measures\n",
      "    |x - x'|               = 0.00e+00 ≤ 0.0e+00\n",
      "    |x - x'|/|x'|          = NaN ≰ 0.0e+00\n",
      "    |f(x) - f(x')|         = NaN ≰ 0.0e+00\n",
      "    |f(x) - f(x')|/|f(x')| = NaN ≰ 0.0e+00\n",
      "    |g(x)|                 = NaN ≰ 1.0e-08\n",
      "\n",
      " * Work counters\n",
      "    Seconds run:   0  (vs limit Inf)\n",
      "    Iterations:    0\n",
      "    f(x) calls:    1\n",
      "    ∇f(x) calls:   1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " NaN\n",
       " NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = BernoulliRegression(;λ=0.0)\n",
    "fit!(reg_model, delta_flashes, choice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
