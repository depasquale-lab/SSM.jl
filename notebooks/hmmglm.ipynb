{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `\\Users\\ryansenne\\Documents\\Github\\SSM`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/Users/ryansenne/Documents/Github/SSM/\")\n",
    "# Pkg.activate(\"/home/ryansenne/PycharmProjects/ssm_julia/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/Users/ryansenne/Documents/Github/SSM//src/SSM.jl\")\n",
    "# include(\"/home/ryansenne/PycharmProjects/ssm_julia/src/SSM.jl\")\n",
    "using Random\n",
    "using .SSM\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian GLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.963508062948609\n",
       "  3.0472521214354646\n",
       " -4.032847152584493\n",
       "  5.085586252239004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a Gaussian GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3);  # 100 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "y = X_concat * β + rand(Normal(0, 1), 10000)\n",
    "\n",
    "# define a GLM\n",
    "glm = GaussianRegression(X, y)\n",
    "fit!(glm, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson GLM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.9972876910665238\n",
       "  3.0018761978448465\n",
       " -4.001568346180793\n",
       "  5.002617122785103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a Poisson GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3);  # 100 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y = Vector{Float64}(rand.(Poisson.(exp.(X_concat * β))))\n",
    "\n",
    "# define a GLM\n",
    "glm = PoissonRegression(X, y)\n",
    "fit!(glm, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial GLM Example (i.e. logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching BinomialRegression(::Matrix{Float64}, ::Vector{Float64}, ::Vector{Float64}, ::LogitLink, ::CrossEntropyLoss)\n\nClosest candidates are:\n  BinomialRegression(::Matrix{T}, ::AbstractVector, !Matched::Bool, ::Link, ::Loss) where T<:Real\n   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n  BinomialRegression(::Matrix{T}, ::AbstractVector, !Matched::Bool, ::Link) where T<:Real\n   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n  BinomialRegression(::Matrix{T}, ::AbstractVector) where T<:Real\n   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching BinomialRegression(::Matrix{Float64}, ::Vector{Float64}, ::Vector{Float64}, ::LogitLink, ::CrossEntropyLoss)\n",
      "\n",
      "Closest candidates are:\n",
      "  BinomialRegression(::Matrix{T}, ::AbstractVector, !Matched::Bool, ::Link, ::Loss) where T<:Real\n",
      "   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n",
      "  BinomialRegression(::Matrix{T}, ::AbstractVector, !Matched::Bool, ::Link) where T<:Real\n",
      "   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n",
      "  BinomialRegression(::Matrix{T}, ::AbstractVector) where T<:Real\n",
      "   @ Main.SSM \\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:231\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] BinomialRegression(X::Matrix{Float64}, y::Vector{Float64}, constant::Bool, link::LogitLink, loss::CrossEntropyLoss)\n",
      "   @ Main.SSM .\\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:239\n",
      " [2] BinomialRegression(X::Matrix{Float64}, y::Vector{Float64})\n",
      "   @ Main.SSM .\\Users\\ryansenne\\Documents\\Github\\SSM\\src\\Regression.jl:232\n",
      " [3] top-level scope\n",
      "   @ c:\\Users\\ryansenne\\Documents\\GitHub\\SSM\\notebooks\\hmmglm.ipynb:17"
     ]
    }
   ],
   "source": [
    "# sigmoid function\n",
    "function sigmoid(x)\n",
    "    return 1 / (1 + exp(-x))\n",
    "end\n",
    "\n",
    "# Fit a Binomial GLM\n",
    "# Generate some synthetic data\n",
    "X = rand(10000, 3); # 1000 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(10000), X)\n",
    "β = [2, 3, -4, 5]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y = Vector{Float64}(rand.(Binomial.(1, sigmoid.(X_concat * β))))\n",
    "\n",
    "# define a GLM\n",
    "glm = BinomialRegression(X, y)\n",
    "fit!(glm, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538958584342558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate AR(1) model\n",
    "init_val = 0.0\n",
    "phi = 0.9\n",
    "sigma = 1.0\n",
    "T = 1000\n",
    "y = Vector{Float64}(undef, T)\n",
    "y[1] = init_val\n",
    "for t in 2:T\n",
    "    y[t] = phi * y[t-1] + rand(Normal(0, sigma))\n",
    "end\n",
    "\n",
    "ar_1 = Autoregression(y, 1)\n",
    "fit!(ar_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Log-likelihood: -8924.586743524973\n",
      "Iteration: 2, Log-likelihood: -8739.362326611385\n",
      "Iteration: 3, Log-likelihood: -8590.645568136204\n",
      "Iteration: 4, Log-likelihood: -8487.922486518475\n",
      "Iteration: 5, Log-likelihood: -8425.134856905965\n",
      "Iteration: 6, Log-likelihood: -8388.1560823782\n",
      "Iteration: 7, Log-likelihood: -8366.508137598063\n",
      "Iteration: 8, Log-likelihood: -8354.032129290421\n",
      "Iteration: 9, Log-likelihood: -8347.05339618205\n",
      "Iteration: 10, Log-likelihood: -8343.28945695505\n",
      "Iteration: 11, Log-likelihood: -8341.336144244464\n",
      "Iteration: 12, Log-likelihood: -8340.358723752062\n",
      "Iteration: 13, Log-likelihood: -8339.884591585684\n",
      "Iteration: 14, Log-likelihood: -8339.660157362405\n",
      "Iteration: 15, Log-likelihood: -8339.55583983571\n",
      "Iteration: 16, Log-likelihood: -8339.507983863976\n",
      "Convergence reached at iteration 16\n",
      "3.0470238249608047e12\n",
      "2.736186558656916e12\n",
      "Initial Variance: [1.5242740495051548e9, 1.3687776681625392e9]\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 1: -1.661341605283923e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 2: -1.6602038867771173e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 3: -1.6586603639019309e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 4: -1.657084862102203e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 5: -1.6570848612305664e7\n",
      "NaN\n",
      "NaN\n",
      "Log-likelihood at iteration 6: -1.6570848612305664e7\n"
     ]
    }
   ],
   "source": [
    "# try out markov glm\n",
    "\n",
    "# Generate synthetic data from two distinct regimes\n",
    "X = rand(1000, 3); # 1000 samples, 3 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(1000), X)\n",
    "β₁ = [-20, -30, -40, 50]\n",
    "β₂ = [6, 7, 8, -9]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y₁ = X_concat * β₁ + rand(Normal(0, 0.1), 1000)\n",
    "y₂ = X_concat * β₂ + rand(Normal(0, 1), 1000)\n",
    "\n",
    "# concatenate X1 and X2\n",
    "x = vcat(X, X)\n",
    "\n",
    "# concatenate y1 and y2\n",
    "y = vcat(y₁, y₂)\n",
    "\n",
    "# define a Gaussian HMMGLM\n",
    "glm = SwitchingGaussianRegression(y, x, 2)\n",
    "\n",
    "MarkovRegressionEM(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " -19.8170073700559\n",
       " -28.185869452125555\n",
       " -37.88979160361808\n",
       "  47.35209106013571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.B[2].regression_model.β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " NaN\n",
       " NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.σ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " -20.058395420154884\n",
       " -28.413295346218813\n",
       " -38.62800924981708\n",
       "  48.29198573140382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.B[2].regression_model.β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Vector{Float64}(::Matrix{Float64})\n\nClosest candidates are:\n  Array{T, N}(::AbstractArray{S, N}) where {T, N, S}\n   @ Base array.jl:621\n  Vector{T}() where T\n   @ Core boot.jl:496\n  Array{T, N}(!Matched::Core.Compiler.BitArray{N}) where {T, N}\n   @ Core bitarray.jl:495\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Vector{Float64}(::Matrix{Float64})\n",
      "\n",
      "Closest candidates are:\n",
      "  Array{T, N}(::AbstractArray{S, N}) where {T, N, S}\n",
      "   @ Base array.jl:621\n",
      "  Vector{T}() where T\n",
      "   @ Core boot.jl:496\n",
      "  Array{T, N}(!Matched::Core.Compiler.BitArray{N}) where {T, N}\n",
      "   @ Core bitarray.jl:495\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] convert(#unused#::Type{Vector{Float64}}, a::Matrix{Float64})\n",
      "   @ Base .\\array.jl:613\n",
      " [2] SwitchingBinomialRegression(y::Vector{Int64}, X::Matrix{Float64}, K::Int64, A::Matrix{Float64}, πₖ::Vector{Float64}, B::Vector{RegressionEmissions}, weights::Matrix{Float64})\n",
      "   @ Main.SSM .\\Users\\ryansenne\\Documents\\Github\\SSM\\src\\MarkovRegression.jl:190\n",
      " [3] SwitchingBinomialRegression(y::Vector{Int64}, X::Matrix{Float64}, k::Int64)\n",
      "   @ Main.SSM .\\Users\\ryansenne\\Documents\\Github\\SSM\\src\\MarkovRegression.jl:211\n",
      " [4] top-level scope\n",
      "   @ c:\\Users\\ryansenne\\Documents\\GitHub\\SSM\\notebooks\\hmmglm.ipynb:20"
     ]
    }
   ],
   "source": [
    "function sigmoid(x)\n",
    "    return 1 / (1 + exp(-x))\n",
    "end\n",
    "\n",
    "# generate observations from a two state hmm-glm with bernoulli emissions\n",
    "X = rand(1000, 2); # 1000 samples, 1 features;\n",
    "# Add a column of ones to represent the intercept term\n",
    "X_concat = hcat(ones(1000), X)\n",
    "β₁ = [0, 1, 2]\n",
    "β₂ = [-1, -1, -1]\n",
    "\n",
    "# Generate some synthetic data\n",
    "y₁ = Vector{Float64}(rand.(Bernoulli.(sigmoid.(X_concat[1:500, :] * β₁))))\n",
    "y₂ = Vector{Float64}(rand.(Bernoulli.(sigmoid.(X_concat[501:end, :] * β₂))))\n",
    "\n",
    "# concatenate ys\n",
    "y = vcat(y₁, y₂)\n",
    "\n",
    "# define a Bernoulli HMMGLM\n",
    "hmmglm = SwitchingBinomialRegression(Int.(y), X_concat[:, 2:3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
